{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "secondary-stock",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m     Cloning\u001b[22m\u001b[39m git-repo `https://github.com/aicenter/GenerativeModels.jl`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/aicenter/GenerativeModels.jl`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ConditionalDists ─ v0.4.10\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatsFuns ──────── v0.9.7\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NNlibCUDA ──────── v0.2.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NNlib ──────────── v0.8.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Zygote ─────────── v0.6.12\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ChainRules ─────── v0.7.70\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatsPlots ─────── v0.14.30\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SpecialFunctions ─ v1.8.3\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DistributionsAD ── v0.6.29\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DiffRules ──────── v1.5.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DrWatson ───────── v2.5.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ChainRulesCore ─── v0.9.45\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Plots ──────────── v1.25.5\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Flux ───────────── v0.12.10\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Reexport ───────── v0.2.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FillArrays ─────── v0.11.9\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LogExpFunctions ── v0.3.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m IPMeasures ─────── v0.2.4\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Distributions ──── v0.24.18\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Interpolations ─── v0.13.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m GR ─────────────── v0.63.1\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Swarm/Project.toml`\n",
      " \u001b[90m [634d3b9d] \u001b[39m\u001b[95m↓ DrWatson v2.9.1 ⇒ v2.5.0\u001b[39m\n",
      " \u001b[90m [587475ba] \u001b[39m\u001b[95m↓ Flux v0.13.1 ⇒ v0.12.10\u001b[39m\n",
      " \u001b[90m [6ac2c632] \u001b[39m\u001b[92m+ GenerativeModels v0.2.3 `https://github.com/aicenter/GenerativeModels.jl#compathelper/new_version/2021-03-29-00-05-30-904-1989780142`\u001b[39m\n",
      " \u001b[90m [06eb3307] \u001b[39m\u001b[95m↓ ManifoldLearning v0.9.0 ⇒ v0.6.2\u001b[39m\n",
      " \u001b[90m [6f286f6a] \u001b[39m\u001b[95m↓ MultivariateStats v0.9.1 ⇒ v0.8.0\u001b[39m\n",
      " \u001b[90m [91a5bcdd] \u001b[39m\u001b[95m↓ Plots v1.29.0 ⇒ v1.25.5\u001b[39m\n",
      " \u001b[90m [f3b207a7] \u001b[39m\u001b[95m↓ StatsPlots v0.14.34 ⇒ v0.14.30\u001b[39m\n",
      " \u001b[90m [e88e6eb3] \u001b[39m\u001b[95m↓ Zygote v0.6.40 ⇒ v0.6.12\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Swarm/Manifest.toml`\n",
      " \u001b[90m [621f4979] \u001b[39m\u001b[95m↓ AbstractFFTs v1.1.0 ⇒ v1.0.1\u001b[39m\n",
      " \u001b[90m [1520ce14] \u001b[39m\u001b[92m+ AbstractTrees v0.3.4\u001b[39m\n",
      " \u001b[90m [7d9f7c33] \u001b[39m\u001b[91m- Accessors v0.1.11\u001b[39m\n",
      " \u001b[90m [dce04be8] \u001b[39m\u001b[91m- ArgCheck v2.3.0\u001b[39m\n",
      " \u001b[90m [7d9fca2a] \u001b[39m\u001b[95m↓ Arpack v0.5.3 ⇒ v0.4.0\u001b[39m\n",
      " \u001b[90m [198e06fe] \u001b[39m\u001b[91m- BangBang v0.3.36\u001b[39m\n",
      " \u001b[90m [9718e550] \u001b[39m\u001b[91m- Baselet v0.1.1\u001b[39m\n",
      " \u001b[90m [49dc2e85] \u001b[39m\u001b[91m- Calculus v0.5.1\u001b[39m\n",
      " \u001b[90m [082447d4] \u001b[39m\u001b[95m↓ ChainRules v1.35.0 ⇒ v0.7.70\u001b[39m\n",
      " \u001b[90m [d360d2e6] \u001b[39m\u001b[95m↓ ChainRulesCore v1.15.0 ⇒ v0.9.45\u001b[39m\n",
      " \u001b[90m [9e997f8a] \u001b[39m\u001b[91m- ChangesOfVariables v0.1.3\u001b[39m\n",
      " \u001b[90m [a33af91c] \u001b[39m\u001b[91m- CompositionsBase v0.1.1\u001b[39m\n",
      " \u001b[90m [c648c4dd] \u001b[39m\u001b[92m+ ConditionalDists v0.4.10\u001b[39m\n",
      " \u001b[90m [187b0558] \u001b[39m\u001b[91m- ConstructionBase v1.3.0\u001b[39m\n",
      " \u001b[90m [6add18c4] \u001b[39m\u001b[91m- ContextVariablesX v0.1.2\u001b[39m\n",
      " \u001b[90m [244e2a9f] \u001b[39m\u001b[91m- DefineSingletons v0.1.2\u001b[39m\n",
      " \u001b[90m [b429d917] \u001b[39m\u001b[91m- DensityInterface v0.4.0\u001b[39m\n",
      " \u001b[90m [b552c78f] \u001b[39m\u001b[95m↓ DiffRules v1.11.0 ⇒ v1.5.0\u001b[39m\n",
      " \u001b[90m [31c24e10] \u001b[39m\u001b[95m↓ Distributions v0.25.59 ⇒ v0.24.18\u001b[39m\n",
      " \u001b[90m [ced4e74d] \u001b[39m\u001b[92m+ DistributionsAD v0.6.29\u001b[39m\n",
      " \u001b[90m [634d3b9d] \u001b[39m\u001b[95m↓ DrWatson v2.9.1 ⇒ v2.5.0\u001b[39m\n",
      " \u001b[90m [fa6b7ba4] \u001b[39m\u001b[91m- DualNumbers v0.6.8\u001b[39m\n",
      " \u001b[90m [cc61a311] \u001b[39m\u001b[91m- FLoops v0.2.0\u001b[39m\n",
      " \u001b[90m [b9860ae5] \u001b[39m\u001b[91m- FLoopsBase v0.1.1\u001b[39m\n",
      " \u001b[90m [1a297f60] \u001b[39m\u001b[95m↓ FillArrays v0.13.2 ⇒ v0.11.9\u001b[39m\n",
      " \u001b[90m [587475ba] \u001b[39m\u001b[95m↓ Flux v0.13.1 ⇒ v0.12.10\u001b[39m\n",
      " \u001b[90m [9c68100b] \u001b[39m\u001b[91m- FoldsThreads v0.1.1\u001b[39m\n",
      " \u001b[90m [069b7b12] \u001b[39m\u001b[91m- FunctionWrappers v1.1.2\u001b[39m\n",
      " \u001b[90m [28b8d3ca] \u001b[39m\u001b[95m↓ GR v0.64.3 ⇒ v0.63.1\u001b[39m\n",
      " \u001b[90m [6ac2c632] \u001b[39m\u001b[92m+ GenerativeModels v0.2.3 `https://github.com/aicenter/GenerativeModels.jl#compathelper/new_version/2021-03-29-00-05-30-904-1989780142`\u001b[39m\n",
      " \u001b[90m [34004b35] \u001b[39m\u001b[91m- HypergeometricFunctions v0.3.10\u001b[39m\n",
      " \u001b[90m [d7dc6e0c] \u001b[39m\u001b[92m+ IPMeasures v0.2.4\u001b[39m\n",
      " \u001b[90m [22cec73e] \u001b[39m\u001b[91m- InitialValues v0.3.1\u001b[39m\n",
      " \u001b[90m [a98d9a8b] \u001b[39m\u001b[95m↓ Interpolations v0.13.6 ⇒ v0.13.2\u001b[39m\n",
      " \u001b[90m [3587e190] \u001b[39m\u001b[91m- InverseFunctions v0.1.4\u001b[39m\n",
      " \u001b[90m [033835bb] \u001b[39m\u001b[91m- JLD2 v0.4.22\u001b[39m\n",
      " \u001b[90m [b14d175d] \u001b[39m\u001b[91m- JuliaVariables v0.2.4\u001b[39m\n",
      " \u001b[90m [e5e0dc1b] \u001b[39m\u001b[92m+ Juno v0.8.4\u001b[39m\n",
      " \u001b[90m [2ab3a3ac] \u001b[39m\u001b[95m↓ LogExpFunctions v0.3.15 ⇒ v0.3.0\u001b[39m\n",
      " \u001b[90m [d8e11817] \u001b[39m\u001b[91m- MLStyle v0.4.11\u001b[39m\n",
      " \u001b[90m [f1d291b0] \u001b[39m\u001b[91m- MLUtils v0.2.5\u001b[39m\n",
      " \u001b[90m [06eb3307] \u001b[39m\u001b[95m↓ ManifoldLearning v0.9.0 ⇒ v0.6.2\u001b[39m\n",
      " \u001b[90m [e89f7d12] \u001b[39m\u001b[92m+ Media v0.5.0\u001b[39m\n",
      " \u001b[90m [128add7d] \u001b[39m\u001b[91m- MicroCollections v0.1.2\u001b[39m\n",
      " \u001b[90m [6f286f6a] \u001b[39m\u001b[95m↓ MultivariateStats v0.9.1 ⇒ v0.8.0\u001b[39m\n",
      " \u001b[90m [872c559c] \u001b[39m\u001b[95m↓ NNlib v0.8.5 ⇒ v0.8.2\u001b[39m\n",
      " \u001b[90m [a00861dc] \u001b[39m\u001b[95m↓ NNlibCUDA v0.2.3 ⇒ v0.2.1\u001b[39m\n",
      " \u001b[90m [77ba4419] \u001b[39m\u001b[95m↓ NaNMath v1.0.0 ⇒ v0.3.7\u001b[39m\n",
      " \u001b[90m [71a1bf82] \u001b[39m\u001b[91m- NameResolution v0.1.5\u001b[39m\n",
      " \u001b[90m [3bd65402] \u001b[39m\u001b[91m- Optimisers v0.2.5\u001b[39m\n",
      " \u001b[90m [ccf2f8ad] \u001b[39m\u001b[95m↓ PlotThemes v3.0.0 ⇒ v2.0.1\u001b[39m\n",
      " \u001b[90m [91a5bcdd] \u001b[39m\u001b[95m↓ Plots v1.29.0 ⇒ v1.25.5\u001b[39m\n",
      " \u001b[90m [8162dcfd] \u001b[39m\u001b[91m- PrettyPrint v0.2.0\u001b[39m\n",
      " \u001b[90m [33c8b6b6] \u001b[39m\u001b[91m- ProgressLogging v0.1.4\u001b[39m\n",
      " \u001b[90m [c1ae055f] \u001b[39m\u001b[91m- RealDot v0.1.0\u001b[39m\n",
      " \u001b[90m [01d81517] \u001b[39m\u001b[95m↓ RecipesPipeline v0.5.2 ⇒ v0.4.1\u001b[39m\n",
      " \u001b[90m [189a3867] \u001b[39m\u001b[95m↓ Reexport v1.2.2 ⇒ v0.2.0\u001b[39m\n",
      " \u001b[90m [efcf1570] \u001b[39m\u001b[91m- Setfield v0.8.2\u001b[39m\n",
      " \u001b[90m [605ecd9f] \u001b[39m\u001b[91m- ShowCases v0.1.0\u001b[39m\n",
      " \u001b[90m [47aef6b3] \u001b[39m\u001b[92m+ SimpleWeightedGraphs v1.2.1\u001b[39m\n",
      " \u001b[90m [276daf66] \u001b[39m\u001b[95m↓ SpecialFunctions v2.1.5 ⇒ v1.8.3\u001b[39m\n",
      " \u001b[90m [171d559e] \u001b[39m\u001b[91m- SplittablesBase v0.1.14\u001b[39m\n",
      " \u001b[90m [82ae8749] \u001b[39m\u001b[93m↑ StatsAPI v1.2.2 ⇒ v1.3.0\u001b[39m\n",
      " \u001b[90m [4c63d2b9] \u001b[39m\u001b[95m↓ StatsFuns v1.0.1 ⇒ v0.9.7\u001b[39m\n",
      " \u001b[90m [f3b207a7] \u001b[39m\u001b[95m↓ StatsPlots v0.14.34 ⇒ v0.14.30\u001b[39m\n",
      " \u001b[90m [28d57a85] \u001b[39m\u001b[91m- Transducers v0.4.73\u001b[39m\n",
      " \u001b[90m [a5390f91] \u001b[39m\u001b[92m+ ZipFile v0.9.4\u001b[39m\n",
      " \u001b[90m [e88e6eb3] \u001b[39m\u001b[95m↓ Zygote v0.6.40 ⇒ v0.6.12\u001b[39m\n",
      " \u001b[90m [9abbd945] \u001b[39m\u001b[92m+ Profile\u001b[39m\n",
      "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m GR → `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/4a740db447aae0fbeb3ee730de1afbb14ac798a1/build.log`\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mReexport\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mAbstractFFTs\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mArpack\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLogExpFunctions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mChainRulesCore\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFillArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mDrWatson\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mNearestNeighborDescent\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mStatsBase\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mInterpolations\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mMLLabelUtils\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mMultivariateStats\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGR\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mNNlib\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mColors\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mMLDataPattern\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mSpecialFunctions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDiffRules\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFFTW\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPrettyTables\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mWidgets\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mClustering\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mChainRules\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStatsFuns\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mManifoldLearning\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mColorVectorSpace\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mWebIO\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mForwardDiff\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mJSExpr\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mNLSolversBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDistributions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mOptimBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mBlink\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mColorSchemes\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mKernelDensity\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLsqFit\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mDistributionsAD\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mPlotlyBase\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPlotUtils\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mUMAP\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mConditionalDists\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mZygote\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mRecipesPipeline\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mPlotlyJS\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mPlotThemes\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mDataFrames\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCUDA\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mIPMeasures\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mNNlibCUDA\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mFlux\n",
      "\u001b[32m  ✓ \u001b[39mPlots\n",
      "\u001b[32m  ✓ \u001b[39mGenerativeModels\n",
      "\u001b[32m  ✓ \u001b[39mStatsPlots\n",
      "  53 dependencies successfully precompiled in 63 seconds (211 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "using Pkg;\n",
    "Pkg.add(url=\"https://github.com/aicenter/GenerativeModels.jl\", rev=\"compathelper/new_version/2021-03-29-00-05-30-904-1989780142\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "blocked-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DrWatson\n",
    "quickactivate(@__DIR__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "electrical-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Swarm/Project.toml`\n",
      " \u001b[90m [c648c4dd] \u001b[39m\u001b[92m+ ConditionalDists v0.4.10\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Swarm/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"ConditionalDists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "hired-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ConditionalDists: SplitLayer\n",
    "using Flux, CSV,DataFrames,MLDataPattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "impaired-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "function normalise(M) \n",
    "    min = minimum(minimum(eachcol(M)))\n",
    "    max = maximum(maximum(eachcol(M)))\n",
    "    return (M .- min) ./ (max - min)\n",
    "end\n",
    "\n",
    "function load_and_normalise_data()\n",
    "    df = DataFrame(CSV.File(\"$(datadir())/exp_raw/data_450.csv\"; types=Float32))\n",
    "    normalised = Array(df) |> normalise\n",
    "    window_size = 60\n",
    "    slidingwindow(normalised',window_size,stride=1)\n",
    "end\n",
    "\n",
    "data = load_and_normalise_data()\n",
    "train_set, validate_set, test_set = splitobs(data, (0.7, 0.2));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "productive-missile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_ae_1d (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_ae_1d()\n",
    "    # Define the encoder and decoder networks \n",
    "    enc_map = Chain(\n",
    "        # 60x900xb\n",
    "        Conv((9,), 450 => 4500, relu; pad=SamePad()),\n",
    "        MaxPool((2,)),\n",
    "        # 30x4500xb\n",
    "        Conv((5,), 4500 => 2250, relu; pad=SamePad()),\n",
    "        MaxPool((2,)),\n",
    "        # 15x2250xb\n",
    "        Conv((3,), 2250 => 1000, relu; pad=SamePad()),\n",
    "        Conv((3,), 1000 => 100, relu; pad=SamePad()),\n",
    "        MaxPool((3,)),\n",
    "        # 5x100xb\n",
    "        Flux.flatten,\n",
    "        SplitLayer( 500,[100,100],[identity, softplus])\n",
    "    )\n",
    "    encoder = ConditionalMvNormal(enc_map)\n",
    "    \n",
    "    dec_map = Chain(\n",
    "        Dense(100, 500),\n",
    "        (x -> reshape(x, 5, 100, :)),\n",
    "        # 5x100xb\n",
    "        ConvTranspose((3,), 100 => 1000, relu; pad=SamePad()),\n",
    "        ConvTranspose((3,), 1000 => 2250, relu; pad=SamePad()),\n",
    "        Upsample((3,)),\n",
    "        # 15x2250xb\n",
    "        ConvTranspose((5,), 2250 => 4500, relu; pad=SamePad()),\n",
    "        Upsample((4,)),\n",
    "        # 60x4500xb\n",
    "        ConvTranspose((9,), 4500 => 450, relu; pad=SamePad()),\n",
    "        # 60x450xb\n",
    "        SplitLayer(60,[450,1],σ)\n",
    "    ) \n",
    "    decoder = ConditionalMvNormal(dec_map)\n",
    "    return VAE(100, encoder, decoder) |> gpu\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "collect-sister",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE:\n",
       " prior   = (DistributionsAD.TuringDiagMvNormal{CUDA.CuArray{Float32, 1, CUDA.Me...)\n",
       " encoder = (ConditionalMvNormal{Chain{Tuple{Conv{1, 2, typeof(relu), CUDA.CuArr...)\n",
       " decoder = (ConditionalMvNormal{Chain{Tuple{Dense{typeof(identity), CUDA.CuArra...)\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_ae_1d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "comprehensive-sewing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x) = -elbo(model,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "tutorial-overhead",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "Out of GPU memory trying to allocate 4.389 MiB\nEffective GPU memory usage: 99.80% (11.760 GiB/11.784 GiB)\nMemory pool usage: 9.778 GiB (9.781 GiB reserved)",
     "output_type": "error",
     "traceback": [
      "Out of GPU memory trying to allocate 4.389 MiB\nEffective GPU memory usage: 99.80% (11.760 GiB/11.784 GiB)\nMemory pool usage: 9.778 GiB (9.781 GiB reserved)",
      "",
      "Stacktrace:",
      "  [1] macro expansion",
      "    @ ~/.julia/packages/CUDA/fAEDi/src/pool.jl:320 [inlined]",
      "  [2] macro expansion",
      "    @ ./timing.jl:299 [inlined]",
      "  [3] #_alloc#204",
      "    @ ~/.julia/packages/CUDA/fAEDi/src/pool.jl:313 [inlined]",
      "  [4] #alloc#203",
      "    @ ~/.julia/packages/CUDA/fAEDi/src/pool.jl:299 [inlined]",
      "  [5] alloc",
      "    @ ~/.julia/packages/CUDA/fAEDi/src/pool.jl:295 [inlined]",
      "  [6] CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}(#unused#::UndefInitializer, dims::Tuple{Int64, Int64})",
      "    @ CUDA ~/.julia/packages/CUDA/fAEDi/src/array.jl:42",
      "  [7] CuArray",
      "    @ ~/.julia/packages/CUDA/fAEDi/src/array.jl:291 [inlined]",
      "  [8] adapt_storage",
      "    @ ~/.julia/packages/CUDA/fAEDi/src/array.jl:539 [inlined]",
      "  [9] adapt_structure",
      "    @ ~/.julia/packages/Adapt/wASZA/src/Adapt.jl:42 [inlined]",
      " [10] adapt",
      "    @ ~/.julia/packages/Adapt/wASZA/src/Adapt.jl:40 [inlined]",
      " [11] #cu#227",
      "    @ ~/.julia/packages/CUDA/fAEDi/src/array.jl:591 [inlined]",
      " [12] cu",
      "    @ ~/.julia/packages/CUDA/fAEDi/src/array.jl:591 [inlined]",
      " [13] adapt_storage",
      "    @ ~/.julia/packages/Flux/7nTyc/src/functor.jl:97 [inlined]",
      " [14] adapt_structure",
      "    @ ~/.julia/packages/Adapt/wASZA/src/Adapt.jl:42 [inlined]",
      " [15] adapt",
      "    @ ~/.julia/packages/Adapt/wASZA/src/Adapt.jl:40 [inlined]",
      " [16] adapt_structure",
      "    @ ~/.julia/packages/Adapt/wASZA/src/wrappers.jl:31 [inlined]",
      " [17] adapt",
      "    @ ~/.julia/packages/Adapt/wASZA/src/Adapt.jl:40 [inlined]",
      " [18] adapt_structure(to::Flux.FluxCUDAAdaptor, A::SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false})",
      "    @ Adapt ~/.julia/packages/Adapt/wASZA/src/wrappers.jl:10",
      " [19] adapt",
      "    @ ~/.julia/packages/Adapt/wASZA/src/Adapt.jl:40 [inlined]",
      " [20] #138",
      "    @ ~/.julia/packages/Flux/7nTyc/src/functor.jl:177 [inlined]",
      " [21] fmap(f::Flux.var\"#138#139\", x::SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}; exclude::typeof(Flux._isbitsarray), walk::typeof(Functors._default_walk), cache::IdDict{Any, Any}, prune::Functors.NoKeyword)",
      "    @ Functors ~/.julia/packages/Functors/qBIlC/src/functor.jl:50",
      " [22] #18",
      "    @ ~/.julia/packages/Functors/qBIlC/src/functor.jl:50 [inlined]",
      " [23] iterate",
      "    @ ./generator.jl:47 [inlined]",
      " [24] collect_to!(dest::Vector{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}}, itr::Base.Generator{SubArray{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}, 1, MLDataPattern.UnlabeledSlidingWindow{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, LearnBase.ObsDim.Last}, Tuple{UnitRange{Int64}}, true}, Functors.var\"#18#19\"{typeof(Flux._isbitsarray), typeof(Functors._default_walk), IdDict{Any, Any}, Functors.NoKeyword, Flux.var\"#138#139\"}}, offs::Int64, st::Tuple{Base.OneTo{Int64}, Int64})",
      "    @ Base ./array.jl:782",
      " [25] collect_to_with_first!(dest::Vector{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}}, v1::SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}, itr::Base.Generator{SubArray{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}, 1, MLDataPattern.UnlabeledSlidingWindow{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, LearnBase.ObsDim.Last}, Tuple{UnitRange{Int64}}, true}, Functors.var\"#18#19\"{typeof(Flux._isbitsarray), typeof(Functors._default_walk), IdDict{Any, Any}, Functors.NoKeyword, Flux.var\"#138#139\"}}, st::Tuple{Base.OneTo{Int64}, Int64})",
      "    @ Base ./array.jl:760",
      " [26] _collect(c::SubArray{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}, 1, MLDataPattern.UnlabeledSlidingWindow{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, LearnBase.ObsDim.Last}, Tuple{UnitRange{Int64}}, true}, itr::Base.Generator{SubArray{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}, 1, MLDataPattern.UnlabeledSlidingWindow{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, LearnBase.ObsDim.Last}, Tuple{UnitRange{Int64}}, true}, Functors.var\"#18#19\"{typeof(Flux._isbitsarray), typeof(Functors._default_walk), IdDict{Any, Any}, Functors.NoKeyword, Flux.var\"#138#139\"}}, #unused#::Base.EltypeUnknown, isz::Base.HasShape{1})",
      "    @ Base ./array.jl:754",
      " [27] collect_similar",
      "    @ ./array.jl:653 [inlined]",
      " [28] map",
      "    @ ./abstractarray.jl:2849 [inlined]",
      " [29] _default_walk",
      "    @ ~/.julia/packages/Functors/qBIlC/src/functor.jl:43 [inlined]",
      " [30] fmap(f::Flux.var\"#138#139\", x::SubArray{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}, 1, MLDataPattern.UnlabeledSlidingWindow{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, LearnBase.ObsDim.Last}, Tuple{UnitRange{Int64}}, true}; exclude::typeof(Flux._isbitsarray), walk::typeof(Functors._default_walk), cache::IdDict{Any, Any}, prune::Functors.NoKeyword)",
      "    @ Functors ~/.julia/packages/Functors/qBIlC/src/functor.jl:50",
      " [31] gpu",
      "    @ ~/.julia/packages/Flux/7nTyc/src/functor.jl:177 [inlined]",
      " [32] |>(x::SubArray{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}, 1, MLDataPattern.UnlabeledSlidingWindow{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, LearnBase.ObsDim.Last}, Tuple{UnitRange{Int64}}, true}, f::typeof(gpu))",
      "    @ Base ./operators.jl:966",
      " [33] top-level scope",
      "    @ In[59]:3",
      " [34] eval",
      "    @ ./boot.jl:373 [inlined]",
      " [35] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "ps = Flux.params(model)\n",
    "opt = ADAM()\n",
    "d = train_set |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ethical-soviet",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "type DataType has no field mutable",
     "output_type": "error",
     "traceback": [
      "type DataType has no field mutable",
      "",
      "Stacktrace:",
      "  [1] getproperty",
      "    @ ./Base.jl:37 [inlined]",
      "  [2] adjoint",
      "    @ ~/.julia/packages/Zygote/zowrf/src/lib/lib.jl:281 [inlined]",
      "  [3] _pullback",
      "    @ ~/.julia/packages/ZygoteRules/AIbCs/src/adjoint.jl:65 [inlined]",
      "  [4] _pullback",
      "    @ ~/.julia/packages/Flux/7nTyc/src/layers/conv.jl:164 [inlined]",
      "  [5] _pullback(ctx::Zygote.Context, f::Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, args::SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false})",
      "    @ Zygote ~/.julia/packages/Zygote/zowrf/src/compiler/interface2.jl:0",
      "  [6] _pullback",
      "    @ ~/.julia/packages/Flux/7nTyc/src/layers/basic.jl:47 [inlined]",
      "  [7] _pullback(::Zygote.Context, ::typeof(Flux.applychain), ::Tuple{Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, typeof(flatten), SplitLayer{Tuple{Dense{typeof(identity), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}}, ::SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false})",
      "    @ Zygote ~/.julia/packages/Zygote/zowrf/src/compiler/interface2.jl:0",
      "  [8] _pullback",
      "    @ ~/.julia/packages/Flux/7nTyc/src/layers/basic.jl:49 [inlined]",
      "  [9] _pullback(ctx::Zygote.Context, f::Chain{Tuple{Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, typeof(flatten), SplitLayer{Tuple{Dense{typeof(identity), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}}}, args::SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false})",
      "    @ Zygote ~/.julia/packages/Zygote/zowrf/src/compiler/interface2.jl:0",
      " [10] _pullback",
      "    @ ~/.julia/packages/ConditionalDists/lR7Nd/src/cond_mvnormal.jl:83 [inlined]",
      " [11] _pullback(::Zygote.Context, ::typeof(condition), ::ConditionalMvNormal{Chain{Tuple{Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, typeof(flatten), SplitLayer{Tuple{Dense{typeof(identity), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}}}}, ::SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false})",
      "    @ Zygote ~/.julia/packages/Zygote/zowrf/src/compiler/interface2.jl:0",
      " [12] _pullback",
      "    @ ~/.julia/packages/ConditionalDists/lR7Nd/src/cond_dist.jl:6 [inlined]",
      " [13] _pullback(::Zygote.Context, ::typeof(rand), ::ConditionalMvNormal{Chain{Tuple{Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, typeof(flatten), SplitLayer{Tuple{Dense{typeof(identity), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}}}}, ::SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false})",
      "    @ Zygote ~/.julia/packages/Zygote/zowrf/src/compiler/interface2.jl:0",
      " [14] _pullback",
      "    @ ~/.julia/packages/GenerativeModels/YFiee/src/vae.jl:60 [inlined]",
      " [15] _pullback(::Zygote.Context, ::GenerativeModels.var\"##elbo#15\", ::Int64, ::typeof(elbo), ::VAE{DistributionsAD.TuringDiagMvNormal{CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, ConditionalMvNormal{Chain{Tuple{Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, typeof(flatten), SplitLayer{Tuple{Dense{typeof(identity), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}}}}, ConditionalMvNormal{Chain{Tuple{Dense{typeof(identity), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, var\"#3#4\", ConvTranspose{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, ConvTranspose{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Upsample{:nearest, Tuple{Int64}, Nothing}, ConvTranspose{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Upsample{:nearest, Tuple{Int64}, Nothing}, ConvTranspose{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, SplitLayer{Tuple{Dense{typeof(σ), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(σ), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}}}}}, ::SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false})",
      "    @ Zygote ~/.julia/packages/Zygote/zowrf/src/compiler/interface2.jl:0",
      " [16] _pullback",
      "    @ ~/.julia/packages/GenerativeModels/YFiee/src/vae.jl:60 [inlined]",
      " [17] _pullback(::Zygote.Context, ::typeof(elbo), ::VAE{DistributionsAD.TuringDiagMvNormal{CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, ConditionalMvNormal{Chain{Tuple{Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Conv{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, MaxPool{1, 2}, typeof(flatten), SplitLayer{Tuple{Dense{typeof(identity), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(softplus), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}}}}, ConditionalMvNormal{Chain{Tuple{Dense{typeof(identity), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, var\"#3#4\", ConvTranspose{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, ConvTranspose{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Upsample{:nearest, Tuple{Int64}, Nothing}, ConvTranspose{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Upsample{:nearest, Tuple{Int64}, Nothing}, ConvTranspose{1, 2, typeof(relu), CUDA.CuArray{Float32, 3, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, SplitLayer{Tuple{Dense{typeof(σ), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Dense{typeof(σ), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}}}}}, ::SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false})",
      "    @ Zygote ~/.julia/packages/Zygote/zowrf/src/compiler/interface2.jl:0",
      " [18] _pullback",
      "    @ ./In[42]:1 [inlined]",
      " [19] _pullback(ctx::Zygote.Context, f::typeof(loss), args::SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false})",
      "    @ Zygote ~/.julia/packages/Zygote/zowrf/src/compiler/interface2.jl:0",
      " [20] _apply",
      "    @ ./boot.jl:814 [inlined]",
      " [21] adjoint",
      "    @ ~/.julia/packages/Zygote/zowrf/src/lib/lib.jl:191 [inlined]",
      " [22] _pullback",
      "    @ ~/.julia/packages/ZygoteRules/AIbCs/src/adjoint.jl:65 [inlined]",
      " [23] _pullback",
      "    @ ~/.julia/packages/Flux/7nTyc/src/optimise/train.jl:110 [inlined]",
      " [24] _pullback(::Zygote.Context, ::Flux.Optimise.var\"#39#45\"{typeof(loss), SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}})",
      "    @ Zygote ~/.julia/packages/Zygote/zowrf/src/compiler/interface2.jl:0",
      " [25] pullback(f::Function, ps::Zygote.Params)",
      "    @ Zygote ~/.julia/packages/Zygote/zowrf/src/compiler/interface.jl:250",
      " [26] gradient(f::Function, args::Zygote.Params)",
      "    @ Zygote ~/.julia/packages/Zygote/zowrf/src/compiler/interface.jl:58",
      " [27] macro expansion",
      "    @ ~/.julia/packages/Flux/7nTyc/src/optimise/train.jl:109 [inlined]",
      " [28] macro expansion",
      "    @ ~/.julia/packages/Juno/n6wyj/src/progress.jl:134 [inlined]",
      " [29] train!(loss::Function, ps::Zygote.Params, data::Vector{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}}, opt::ADAM; cb::Flux.Optimise.var\"#40#46\")",
      "    @ Flux.Optimise ~/.julia/packages/Flux/7nTyc/src/optimise/train.jl:107",
      " [30] train!(loss::Function, ps::Zygote.Params, data::Vector{SubArray{Float32, 2, LinearAlgebra.Adjoint{Float32, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}}, false}}, opt::ADAM)",
      "    @ Flux.Optimise ~/.julia/packages/Flux/7nTyc/src/optimise/train.jl:105",
      " [31] top-level scope",
      "    @ ./In[58]:7",
      " [32] eval",
      "    @ ./boot.jl:373 [inlined]",
      " [33] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "\n",
    "for e in 1:5\n",
    "#     @info \"Epoch $e\" loss(train_set)\n",
    "    Flux.train!(loss, ps, d, opt)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-florist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
